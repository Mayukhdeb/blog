<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta property="og:title" content=" Exploring the Movement Database &middot;  @mayukhdeb" />
  <meta property="og:site_name" content="@mayukhdeb" />
  <meta property="og:url" content="https://mayukhdeb.github.io/blog/post/gsoc-2020-may-24/" />
  <meta name="theme" content="darksimplicity">
  <meta name="generator" content="Hugo 0.72.0" />
  
  
  <base href="https://mayukhdeb.github.io/blog/">
  <title> Exploring the Movement Database &middot;  @mayukhdeb</title>
  <link rel="stylesheet" href="https://mayukhdeb.github.io/blog/css/style.min.css">

</head>
<body>
  <header>
      <nav role="top-nav">
          <ul class="navbar-list">
            
            <li class="navbar-item"><a class="navbar-link" href="https://github.com/Mayukhdeb">Github</a></li>
            <li class="navbar-item"><a class="navbar-link" href="https://twitter.com/mayukh091">Twitter</a></li>
          </ul>
      </nav>
      <br />
      <h1><a href="https://mayukhdeb.github.io/blog/" class="title">@mayukhdeb</a>
        
      </h1>
  </header>
  <main>
      <article itemscope itemtype="http://schema.org/Blog">
        <h3><a class="post-title-link" href="https://mayukhdeb.github.io/blog/post/gsoc-2020-may-24/">Exploring the Movement Database</a></h3>
        
            <div class="tags">tags: &nbsp;
              <span itemprop="keywords"><a class="tag-link" href="https://mayukhdeb.github.io/blog/tags/gsoc" rel="tag">GSoC </a><a class="tag-link" href="https://mayukhdeb.github.io/blog/tags/computer-vision" rel="tag">Computer vision </a><a class="tag-link" href="https://mayukhdeb.github.io/blog/tags/deep-learning" rel="tag">Deep learning </a><a class="tag-link" href="https://mayukhdeb.github.io/blog/tags/openworm" rel="tag">OpenWorm </a><a class="tag-link" href="https://mayukhdeb.github.io/blog/tags/feature-extraction" rel="tag">Feature extraction </a>
              </span>
          </div>
          <div class="content-full"><p>After week 1, the new priority was to find the right data on the internet. I started the week off by reading papers based on locomotion in the C. elegans worm. Surprisingly enough (or unsurprisingly, depending on how much you&rsquo;re into worms), most of the data was from the <a href="http://movement.openworm.org/">OpenWorm Movement Database</a>.</p>
<p>Almost all the video data on the database is from the <a href="https://github.com/ver228/tierpsy-tracker">Tierpsy tracker</a>, which is an amazing worm tracking tool in itself. But there was a new hurdle now.</p>
<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/initial_image.png" width="60%"/> 
</figure>

<p>The issue with the video data (as seen above) wThe issue with the video data (as seen above) was that the worms were &ldquo;partially segmented out&rdquo;. Which meant that the background was all blacked out except for a small &ldquo;padding area&rdquo; around the worm. This &ldquo;padding area&rdquo; was a good safety measure on the Tierpsy tracker&rsquo;s side, but was a minor hurdle  for someone who wanted to segment out just the worm from the image in order to gain inferences from behavioural dynamics.</p>
<p>This hurdle was taken care of in 3 stages:</p>
<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/OW_movement_database_pipeline.png" width="100%"/> 
</figure>

<ol>
<li>
<p>Stage 1: Extracting the &ldquo;padding region&rdquo; around the worm with <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html"><code>cv2.threshold()</code></a></p>
</li>
<li>
<p>Stage 2: Removing the padding region by using <a href="https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html"><code>cv2.bitwise_and()</code></a> between the real and the thresholded image</p>
</li>
<li>
<p>Removing any extra noise (as seen on stage 2) with <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html"><code>cv2.erode()</code></a></p>
</li>
</ol>
<p>Now the next objecive was to extract the head and tail, this was done  using corner detection with <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html#goodfeaturestotrack"><code>cv2.goodFeaturesToTrack()</code></a> with <code>maxCorners = 2</code> to only capture the 2 most prominent corners.</p>
<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/head_and_tail.png" width="60%"/> 
</figure>

<p>To complete the skeletonization, all that was needed now was to skeletonize the main body, and that was done with the very self explanatory function named <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html"><code>skimage.morphology.skeletonize()</code></a>. Combined with two circles which signify the head and the tail, we get a clean skeleton which can now be used for analysis on a bigger scale with a large number of frames.</p>
<p><figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/skeleton.png" width="60%"/> 
</figure>

<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/skeleton_long.png" width="60%"/> 
</figure>
as that the worms were &ldquo;partially segmented out&rdquo;. Which meant that the background was all blacked out except for a small &ldquo;padding area&rdquo; around the worm. This &ldquo;padding area&rdquo; was a good safety measure on the Tierpsy tracker&rsquo;s side, but was a minor hurdle  for someone who wanted to segment out just the worm from the image in order to gain inferences from behavioural dynamics.</p>
<p>This hurdle was taken care of in 3 stages:</p>
<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/OW_movement_database_pipeline.png" width="100%"/> 
</figure>

<ol>
<li>
<p>Stage 1: Extracting the &ldquo;padding region&rdquo; around the worm with <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html"><code>cv2.threshold()</code></a></p>
</li>
<li>
<p>Stage 2: Removing the padding region by using <a href="https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html"><code>cv2.bitwise_and()</code></a> between the real and the thresholded image</p>
</li>
<li>
<p>Removing any extra noise (as seen on stage 2) with <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html"><code>cv2.erode()</code></a></p>
</li>
</ol>
<p>Now the next objecive was to extract the head and tail, this was done  using corner detection with <a href="https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html#goodfeaturestotrack"><code>cv2.goodFeaturesToTrack()</code></a> with <code>maxCorners = 2</code> to only capture the 2 most prominent corners.</p>
<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/head_and_tail.png" width="60%"/> 
</figure>

<p>To complete the skeletonization, all that was needed now was to skeletonize the main body, and that was done with the very self explanatory function named <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html"><code>skimage.morphology.skeletonize()</code></a>. Combined with two circles which signify the head and the tail, we get a clean skeleton which can now be used for analysis on a bigger scale with a large number of frames.</p>
<p><figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/skeleton.png" width="60%"/> 
</figure>

<figure>
    <img src="https://mayukhdeb.github.io/blog/post/images/may_24/skeleton_long.png" width="60%"/> 
</figure>
</p>

</div>
      </article>
  </main>
  <footer>
      <div class="copyright"><p>&copy; 2020. @mayukhdeb. All rights reserved. </div>    

  </footer>
</body>
</html>

