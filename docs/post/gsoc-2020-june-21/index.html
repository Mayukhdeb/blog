<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Training the segmentation model | @mayukhdeb</title>

<meta name="keywords" content="GSoC, OpenWorm, deep learning, semantic segmentation" />
<meta name="description" content="Google summer of code week 6">
<meta name="author" content="">
<link rel="canonical" href="https://mayukhdeb.github.io/blog/post/gsoc-2020-june-21/" />
<link href="https://mayukhdeb.github.io/blog/assets/css/stylesheet.min.d1bc2b736056bd5698d770eeedc08a73bce9e6cebb30810f6f1b2c2048e46ab8.css" integrity="sha256-0bwrc2BWvVaY13Du7cCKc7zp5s67MIEPbxssIEjkarg=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://mayukhdeb.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://mayukhdeb.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://mayukhdeb.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://mayukhdeb.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://mayukhdeb.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.68.3" />


<meta property="og:title" content="Training the segmentation model" />
<meta property="og:description" content="Google summer of code week 6" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mayukhdeb.github.io/blog/post/gsoc-2020-june-21/" />
<meta property="article:published_time" content="2020-06-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-21T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Training the segmentation model"/>
<meta name="twitter:description" content="Google summer of code week 6"/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Training the segmentation model",
  "name": "Training the segmentation model",
  "description": "Google Summer of Code | Coding period week 3",
  "keywords": [
    "GSoC", "OpenWorm", "deep learning", "semantic segmentation"
  ],
  "articleBody": "The objective of week 3 was to train the model initially on a dummy dataset(for prototyping) and then on a larger dataset. Check out this notebook if you want to have a better look.\nThe three primary conponents of our training pipeline were:\n  PyTorch for building, training and deploying the models.\n  albumentations for building the image augmentation pipeline. It was important for us to make sure that the image and the mask went through the same exact set of transforms whenever they’re loaded into the batch, and this was possible in this library.\n  segmentation-models-pytorch is a high level API to build models for multi class (or binary) image segmentation.\n   The issue with interpolation The problem with the image loading class was that the pixel values were getting altered due to the resizing interpolations. This was fixed (or so I thought) with a manual override with mask[mask != 0] = 255. It converted all the non zero values to 255 forcefully, just like it was before going through the augmentative transforms.\nInterestingly enough, I faced this problem even after using the manual fix. But this time it was because of the transforms.resize function within the torchvision.transforms. The problem was traced down to the interpolation, the very fact that the default interpolation was set to Image.BILINEAR (default arg) was the reason why the pixel values were getting altered in the mask. This was fixed by setting interpolation = Image.NEAREST.\nAfter all of these transforms, the training images and masks came out to be as shown:\n   The model The next step was to train the model on the images, and for our case, we used the pre-trained ResNet18 as the encoder. Some of the other parameters used are as follows:\n  ACTIVATION = 'sigmoid' clamps the output pixel values between [0.,1.], which are ideal for calculating a loss with respect to a mask whose pixel values also are within the same range.\n  DEVICE = 'cuda' moves the model to the GPU for training.\n  in_channels = 1 means the model takes grayscale images as input.\n  The loss function The Intersection Over Union score (also known as Jaccard Index) is a statistic used for gauging the similarity and diversity of sample sets. It is defined as:\n    Dice Coefficient can be seen as the percentage of overlap between the two sets, that is a number between 0 and 1. DiceLoss() can be mathematically defined as 1 - dice_coefficient:\n  Where |X| ∩ |Y| is the intersection where the prediction correctly overlaps the label in the 2D mask.\nTraining metrics and visualizing the outputs The model could hit an IOU score of just above 0.7 after 24 epochs of training.\n  And when combined with some thresholding on the predicted images, here are the predicted results:\n  ",
  "wordCount" : "456",
  "inLanguage": "en",
  "datePublished": "2020-06-21T00:00:00Z",
  "dateModified": "2020-06-21T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mayukhdeb.github.io/blog/post/gsoc-2020-june-21/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "@mayukhdeb",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mayukhdeb.github.io/blog/favicon.ico"
    }
  }
}
</script>



</head>

<body class="">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mayukhdeb.github.io/blog/" accesskey="h" title="@mayukhdeb (Alt + H)">@mayukhdeb</a>
            <span class="logo-switches">
                <span class="theme-toggle" title="(Alt + T)">
                    <a id="theme-toggle" accesskey="t">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </a>
                </span>
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()"></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">
      Training the segmentation model
    </h1>
    <div class="post-meta">June 21, 2020

    </div>
  </header> 

  <div class="post-content">
<p>The objective of week 3 was to train the model initially on a dummy dataset(for prototyping) and then on a larger dataset. Check out <a href="https://nbviewer.jupyter.org/github/devoworm/GSoC-2020/blob/master/Pre-trained%20Models%20%28DevLearning%29/notebooks/embryo_segmentation/train_segmentation_model.ipynb">this notebook</a> if you want to have a better look.</p>
<p>The three primary conponents of our training pipeline were:</p>
<ul>
<li>
<p><a href="https://pytorch.org/">PyTorch</a> for building, training and deploying the models.</p>
</li>
<li>
<p><a href="https://github.com/albumentations-team/albumentations">albumentations</a> for building the image augmentation pipeline. It was important for us to make sure that the image and the mask went through the same exact set of transforms whenever they&rsquo;re loaded into the batch, and this was possible in this library.</p>
</li>
<li>
<p><a href="https://github.com/qubvel/segmentation_models.pytorch">segmentation-models-pytorch</a> is a high level API to build models for multi class (or binary) image segmentation.</p>
</li>
</ul>
<hr>
<h2 id="the-issue-with-interpolation">The issue with interpolation<a hidden class="anchor" aria-hidden="true" href="#the-issue-with-interpolation">#</a></h2>
<p>The problem with the image loading class was that the pixel values were getting altered due to the resizing interpolations. This was fixed (or so I thought) with a manual override with <code>mask[mask != 0] = 255</code>. It converted all the non zero values to 255 forcefully, just like it was before going through the augmentative transforms.</p>
<p>Interestingly enough, I faced this problem even after using the manual fix. But this time it was because of the <code>transforms.resize</code> function within the <code>torchvision.transforms</code>. The problem was traced down to the interpolation, the very fact that the default interpolation was set to <code>Image.BILINEAR</code> (default arg) was the reason why the pixel values were getting altered in the mask. This was fixed by setting <code>interpolation = Image.NEAREST</code>.</p>
<p>After all of these transforms, the training images and masks came out to be as shown:</p>
<figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/train_image.png" width="20%"/> 
</figure>

<hr>
<h2 id="the-model">The model<a hidden class="anchor" aria-hidden="true" href="#the-model">#</a></h2>
<p>The next step was to train the model on the images, and for our case, we used the <a href="https://supervise.ly/explore/models/res-net-18-image-net-2717/overview">pre-trained ResNet18</a> as the encoder. Some of the other parameters used are as follows:</p>
<ul>
<li>
<p><code>ACTIVATION = 'sigmoid'</code> clamps the output pixel values between <code>[0.,1.]</code>, which are ideal for calculating a loss with respect to a mask whose pixel values also are within the same range.</p>
</li>
<li>
<p><code>DEVICE = 'cuda'</code> moves the model to the GPU for training.</p>
</li>
<li>
<p><code>in_channels = 1</code> means the model takes grayscale images as input.</p>
</li>
</ul>
<h2 id="the-loss-function">The loss function<a hidden class="anchor" aria-hidden="true" href="#the-loss-function">#</a></h2>
<p>The <a href="https://en.wikipedia.org/wiki/IOU"><strong>Intersection Over Union</strong></a> score (also known as Jaccard Index) is a statistic used for gauging the similarity and diversity of sample sets. It is defined as:</p>
<p><figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/iou_score.png" width="30%"/> 
</figure>

<figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/iou.png" width="30%"/> 
</figure>
</p>
<p><a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient"><strong>Dice Coefficient</strong></a> can be seen as the percentage of overlap between the two sets, that is a number between 0 and 1. <code>DiceLoss()</code> can be mathematically defined as  <code>1 - dice_coefficient</code>:</p>
<figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/diceloss.png" width="30%"/> 
</figure>

<p>Where <code>|X| ∩ |Y|</code>  is the intersection where the prediction correctly overlaps the label in the 2D mask.</p>
<h2 id="training-metrics-and-visualizing-the-outputs">Training metrics and visualizing the outputs<a hidden class="anchor" aria-hidden="true" href="#training-metrics-and-visualizing-the-outputs">#</a></h2>
<p>The model could hit an IOU score of just above 0.7 after 24 epochs of training.</p>
<figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/training_curve.png" width="30%"/> 
</figure>

<p>And when combined with some thresholding on the predicted images, here are the predicted results:</p>
<figure>
    <img src="https://raw.githubusercontent.com/Mayukhdeb/blog/master/content/post/images/june_21/seg_results.png" width="50%"/> 
</figure>


</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://mayukhdeb.github.io/blog/tags/deep-learning/">Deep learning</a></li>
      <li><a href="https://mayukhdeb.github.io/blog/tags/gsoc/">GSoC</a></li>
      <li><a href="https://mayukhdeb.github.io/blog/tags/openworm/">OpenWorm</a></li>
      <li><a href="https://mayukhdeb.github.io/blog/tags/semantic-segmentation/">semantic segmentation</a></li>
    </ul>
  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://mayukhdeb.github.io/blog/">@mayukhdeb</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<button class="top-link" id="top-link" type="button" aria-label="go to top" title="Go to Top (Alt + G)" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
        <path d="M12 6H0l6-6z" /></svg>
</button>



<script defer src="https://mayukhdeb.github.io/blog/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js" integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
    mybutton.onclick = function () {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
        window.location.hash = ''
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
